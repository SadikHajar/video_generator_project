import os
import json
import time
import requests
from dotenv import load_dotenv
import random



load_dotenv()
API_URL = "https://api.synthesia.io/v2/videos"
API_KEY = os.getenv("SYNTHESIA_API_KEY")

AVATAR_IDS = [
    "anna_costume1_cameraA",
    "james_costume1_cameraA",
    "mike_costume1_cameraA"
]

# Choisir un avatar au hasard pour cette vidÃ©o
selected_avatar = random.choice(AVATAR_IDS)
print(f"ğŸ­ Avatar sÃ©lectionnÃ© alÃ©atoirement : {selected_avatar}")

def detect_language_and_create_intro(titre_formation, objectifs):
    """DÃ©tecte la langue et crÃ©e l'introduction appropriÃ©e"""
    
    # âœ… DÃ©tecter la langue en analysant le titre et les objectifs
    sample_text = titre_formation + " " + " ".join(objectifs[:2]) if objectifs else titre_formation
    
    # Simple dÃ©tection basÃ©e sur des mots-clÃ©s
    french_keywords = ['formation', 'cours', 'apprentissage', 'dÃ©veloppement', 'compÃ©tences', 'savoir']
    english_keywords = ['training', 'course', 'learning', 'development', 'skills', 'knowledge', 'understanding']
    
    sample_lower = sample_text.lower()
    
    # Compter les occurrences de mots-clÃ©s
    french_score = sum(1 for word in french_keywords if word in sample_lower)
    english_score = sum(1 for word in english_keywords if word in sample_lower)
    
    # DÃ©terminer la langue
    if english_score > french_score:
        language = 'en'
    else:
        language = 'fr'  # FranÃ§ais par dÃ©faut
    
    # âœ… Templates d'introduction par langue
    templates = {
        'fr': {
            'greeting': "Bonjour et bienvenue dans cette formation sur {titre}.",
            'objectives_intro': " Ã€ la fin de cette formation, vous serez capable de :",
            'closing': " CommenÃ§ons sans plus attendre !",
            'key_points_title': "Points clÃ©s :"
        },
        'en': {
            'greeting': "Hello and welcome to this training on {titre}.",
            'objectives_intro': " By the end of this training, you will be able to:",
            'closing': " Let's get started!",
            'key_points_title': "Key Points:"
        }
    }
    
    template = templates[language]
    intro_text = template['greeting'].format(titre=titre_formation)
    
    if objectifs:
        intro_text += template['objectives_intro']
        for i, objectif in enumerate(objectifs, 1):
            intro_text += f" {i}. {objectif}."
        intro_text += template['closing']
    
    print(f"ğŸŒ Langue dÃ©tectÃ©e: {language.upper()}")
    return intro_text, language

def create_video_from_script(json_file_path):
    if not API_KEY:
        raise ValueError("âŒ SYNTHESIA_API_KEY manquante dans .env")

    if not API_KEY.strip():
        raise ValueError("âŒ SYNTHESIA_API_KEY est vide dans .env")

    with open(json_file_path, 'r', encoding='utf-8') as f:
        script_data = json.load(f)
    
    

    clips = []

    titre_formation = script_data.get("titre_formation", "Formation IA")
    objectifs = script_data.get("objectifs", [])
    

    # âœ… Utiliser la fonction de dÃ©tection de langue au lieu du texte franÃ§ais codÃ© en dur
    intro_text, detected_language = detect_language_and_create_intro(titre_formation, objectifs)
    intro_clip = {
        "scriptText": intro_text,
        "avatar": selected_avatar,
        "background": "off_white",
        "avatarSettings": {
            "horizontalAlign": "center",
            "style": "rectangular", 
            "scale": 1.0
        }
    }
    clips.append(intro_clip)

    # âœ… Titre pour les points clÃ©s selon la langue
    key_points_title = "Points clÃ©s :" if detected_language == 'fr' else "Key Points:"

    for scene in script_data.get('scenes', []):
        voix_off_content = scene.get('voix_off')
        elements_visuels = scene.get('elements_visuels') 
        points_cles = scene.get('points_cles', [])  # URL de l'image
        if voix_off_content and voix_off_content.strip():
            clip = {
                "scriptText": voix_off_content.strip(),  # âœ… Directement la string, pas un objet
                "avatar": selected_avatar,
                "background": "off_white",
                "avatarSettings": {
                    "horizontalAlign": "center",
                    "style": "rectangular", 
                    "scale": 1.0
                }
            }

            

            # âœ… Ajouter l'image si elle existe
            if elements_visuels and elements_visuels.strip():
                clip["background"] = elements_visuels.strip()
                print(f"ğŸ–¼ï¸ ScÃ¨ne {scene.get('numero', 'N/A')}: Image ajoutÃ©e - {elements_visuels}")
            else:
                clip["background"] = "off_white"  # Background par dÃ©faut
                print(f"ğŸ“„ ScÃ¨ne {scene.get('numero', 'N/A')}: Background par dÃ©faut")
            clips.append(clip)
        else:
            print(f"âš ï¸ ScÃ¨ne {scene.get('numero', 'N/A')} ignorÃ©e car la voix_off est vide.")
        # âœ… Ajouter les points clÃ©s comme texte overlay (selon la documentation)
            if points_cles and len(points_cles) > 0:
                texts = []
                
                # Titre des points clÃ©s
                title_text = {
                    "text": key_points_title,
                    "x": 50,
                    "y": 100,
                    "fontSize": 24,
                    "fontWeight": "bold",
                    "color": "#FFFFFF",
                    "backgroundColor": "rgba(0, 100, 200, 0.8)",
                    "padding": 10,
                    "borderRadius": 5
                }
                texts.append(title_text)
                
                # Points clÃ©s individuels
                for i, point in enumerate(points_cles):
                    point_text = {
                        "text": f"â€¢ {point}",
                        "x": 50,
                        "y": 150 + (i * 40),  # Espacement vertical de 40px
                        "fontSize": 18,
                        "color": "#FFFFFF",
                        "backgroundColor": "rgba(25, 135, 84, 0.7)",
                        "padding": 8,
                        "borderRadius": 5,
                        "maxWidth": 300
                    }
                    texts.append(point_text)
                
                clip["texts"] = texts
                print(f"ğŸ“‹ ScÃ¨ne {scene.get('numero', 'N/A')}: {len(points_cles)} points clÃ©s ajoutÃ©s comme texte")
            else:
                print(f"ğŸ“„ ScÃ¨ne {scene.get('numero', 'N/A')}: Pas de points clÃ©s")
            
            clips.append(clip)
    else:
        print(f"âš ï¸ ScÃ¨ne {scene.get('numero', 'N/A')} ignorÃ©e car la voix_off est vide.")

    if not clips:
        print("âŒ Aucune scÃ¨ne valide avec voix_off trouvÃ©e.")
        return None

    payload = {
        "test": True,
        "title": titre_formation,
        "description": script_data.get("description", ""),
        "visibility": "private",
        "input": clips
    }

    headers = {
        "Content-Type": "application/json",
         "Authorization": f"{API_KEY}" 
    }

    print("ğŸ“¡ Envoi de la requÃªte Ã  Synthesia...")
    print(f"ğŸ” Nombre de clips: {len(clips)}")
    points_utilisÃ©s = [len(clip.get('texts', [])) for clip in clips[1:]]  # Exclure l'intro
    print(f"ğŸ“‹ Points clÃ©s par scÃ¨ne: {points_utilisÃ©s}")
   
    images_utilisees = [
    clip['background'] if isinstance(clip.get('background'), str) and clip['background'].startswith("http") else "Aucune"
    for clip in clips[1:]  # on saute l'intro
]
    
    print(f"ğŸ–¼ï¸ Images utilisÃ©es dans les scÃ¨nes :")
    for i, img in enumerate(images_utilisees, start=1):
        print(f"   - ScÃ¨ne {i}: {img}")
    
    print(f"ğŸ” Sample clip format: {json.dumps(clips[0] if clips else {}, indent=2)}")
    
    try:
        response = requests.post(API_URL, headers=headers, json=payload)
        
        if response.status_code in [200, 201]:
            video_data = response.json()
            video_id = video_data.get("id")
            print(f"âœ… VidÃ©o crÃ©Ã©e avec succÃ¨s ! ID: {video_id}")
            download_url = wait_for_video_completion(video_id)
            if download_url:
                print(f"ğŸ¬ VidÃ©o prÃªte ! Lien de tÃ©lÃ©chargement : {download_url}")
                print(f"ğŸŒ Ou consultez sur Synthesia : https://app.synthesia.io/video/{video_id}")
                return download_url
            else:
                print(f"â³ VidÃ©o en cours de gÃ©nÃ©ration. Consultez : https://app.synthesia.io/video/{video_id}")
                return f"https://app.synthesia.io/video/{video_id}"
            
        else:
            print(f"âŒ Erreur HTTP: {response.status_code}")
            print(f"ğŸ“„ RÃ©ponse complÃ¨te: {response.text}")
            return None
            
    except Exception as err:
        print(f"ğŸ’¥ Erreur lors de la crÃ©ation: {err}")
        return None
def wait_for_video_completion(video_id):
    """Attend que la vidÃ©o soit prÃªte et rÃ©cupÃ¨re le lien de tÃ©lÃ©chargement"""
    headers = {
        "Authorization": f"{API_KEY}",
        "Content-Type": "application/json"
    }
    
    status_url = f"https://api.synthesia.io/v2/videos/{video_id}"
    max_attempts = 180 # Maximum 5 minutes d'attente
    
    print("â³ VÃ©rification du statut de la vidÃ©o...")
    
    for attempt in range(max_attempts):
        try:
            response = requests.get(status_url, headers=headers)
            
            if response.status_code == 200:
                video_info = response.json()
                status = video_info.get('status')
                
                print(f"ğŸ“Š Statut: {status}")
                
                if status == "complete":
                    download_url = video_info.get('download')
                    if download_url:
                        return download_url
                    else:
                        print("âš ï¸ VidÃ©o complÃ¨te mais pas de lien de tÃ©lÃ©chargement")
                        return None
                        
                elif status == "failed":
                    print("âŒ La gÃ©nÃ©ration de la vidÃ©o a Ã©chouÃ©")
                    return None
                    
                elif status in ["in_progress", "queued"]:
                    print(f"â³ GÃ©nÃ©ration en cours... (tentative {attempt + 1}/{max_attempts})")
                    time.sleep(10)  # Attendre 10 secondes
                    continue
                    
            else:
                print(f"âŒ Erreur lors de la vÃ©rification: {response.status_code}")
                return None
                
        except Exception as e:
            print(f"ğŸ’¥ Erreur lors de la vÃ©rification: {e}")
            return None
    
    print("â° Timeout: La vidÃ©o prend plus de temps que prÃ©vu Ã  Ãªtre gÃ©nÃ©rÃ©e")
    return None  